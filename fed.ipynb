{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from client_utils import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_type</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>DR</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>DR</td>\n",
       "      <td>Proliferate_DR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>DR</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>No_DR</td>\n",
       "      <td>No_DR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>No_DR</td>\n",
       "      <td>No_DR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis binary_type            type\n",
       "0  000c1434d8d7          2          DR        Moderate\n",
       "1  001639a390f0          4          DR  Proliferate_DR\n",
       "2  0024cdab0c1e          1          DR            Mild\n",
       "3  002c21358ce6          0       No_DR           No_DR\n",
       "4  005b95c28852          0       No_DR           No_DR"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an additional column, mapping to the type\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "diagnosis_dict_binary = {\n",
    "    0: 'No_DR',\n",
    "    1: 'DR',\n",
    "    2: 'DR',\n",
    "    3: 'DR',\n",
    "    4: 'DR'\n",
    "}\n",
    "\n",
    "diagnosis_dict = {\n",
    "    0: 'No_DR',\n",
    "    1: 'Mild',\n",
    "    2: 'Moderate',\n",
    "    3: 'Severe',\n",
    "    4: 'Proliferate_DR',\n",
    "}\n",
    "\n",
    "\n",
    "df['binary_type'] =  df['diagnosis'].map(diagnosis_dict_binary.get)\n",
    "df['type'] = df['diagnosis'].map(diagnosis_dict.get)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data folder\n",
    "img_path = 'gaussian_filtered_images/imgs'\n",
    "\n",
    "#the path list \n",
    "image_paths = list(paths.list_images(img_path))\n",
    "\n",
    "image_list = load(image_paths, verbose=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['diagnosis','binary_type'],axis=1)\n",
    "df['id_code'] = df['id_code']+\".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "label_list = lb.fit_transform(df['type'])\n",
    "label_df = pd.DataFrame(label_list,columns=lb.classes_)\n",
    "df = pd.concat([df,label_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_list, label_list, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(image_list, label_list, num_clients=10, initial='clients'):\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "    #randomize the data\n",
    "    data = list(zip(image_list, label_list))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    #shard data and place at each client\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clients\n",
    "clients = create_clients(X_train, y_train, num_clients=10, initial='client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15197\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01 \n",
    "comms_round = 100\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = SGD(lr=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.9\n",
    "               )         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 50176), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "#randomize client data - using keys\n",
    "client_names= list(clients_batched.keys())\n",
    "random.shuffle(client_names)\n",
    "for client in client_names:\n",
    "    print(clients_batched[client])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 0 | global_acc: 47.411% | global_loss: 1.5259757041931152\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 1 | global_acc: 47.411% | global_loss: 1.4899598360061646\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "comm_round: 2 | global_acc: 47.411% | global_loss: 1.490692377090454\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 3 | global_acc: 47.411% | global_loss: 1.4905803203582764\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 4 | global_acc: 47.411% | global_loss: 1.490466594696045\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 5 | global_acc: 47.411% | global_loss: 1.4897032976150513\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 6 | global_acc: 47.411% | global_loss: 1.4901502132415771\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 7 | global_acc: 47.411% | global_loss: 1.4902567863464355\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 8 | global_acc: 47.411% | global_loss: 1.4906164407730103\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 9 | global_acc: 47.411% | global_loss: 1.490216612815857\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 10 | global_acc: 47.411% | global_loss: 1.49010169506073\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 11 | global_acc: 47.411% | global_loss: 1.4903944730758667\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "comm_round: 12 | global_acc: 47.411% | global_loss: 1.4892317056655884\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 13 | global_acc: 47.411% | global_loss: 1.490737795829773\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 14 | global_acc: 47.411% | global_loss: 1.4903656244277954\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 15 | global_acc: 47.411% | global_loss: 1.4898937940597534\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 16 | global_acc: 47.411% | global_loss: 1.4899359941482544\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 17 | global_acc: 47.411% | global_loss: 1.490604043006897\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 18 | global_acc: 47.411% | global_loss: 1.4898121356964111\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 19 | global_acc: 47.411% | global_loss: 1.489975094795227\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 20 | global_acc: 47.411% | global_loss: 1.4905083179473877\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 21 | global_acc: 47.411% | global_loss: 1.4905141592025757\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 22 | global_acc: 47.411% | global_loss: 1.490813136100769\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 23 | global_acc: 47.411% | global_loss: 1.490039587020874\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 24 | global_acc: 47.411% | global_loss: 1.4903199672698975\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 25 | global_acc: 47.411% | global_loss: 1.490031123161316\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 26 | global_acc: 47.411% | global_loss: 1.490200161933899\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 27 | global_acc: 47.411% | global_loss: 1.4905891418457031\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 28 | global_acc: 47.411% | global_loss: 1.4903779029846191\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 29 | global_acc: 47.411% | global_loss: 1.49049711227417\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 30 | global_acc: 47.411% | global_loss: 1.490713119506836\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 31 | global_acc: 47.411% | global_loss: 1.4905651807785034\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 32 | global_acc: 47.411% | global_loss: 1.4907904863357544\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 33 | global_acc: 47.411% | global_loss: 1.4901701211929321\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "comm_round: 34 | global_acc: 47.411% | global_loss: 1.4907209873199463\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 35 | global_acc: 47.411% | global_loss: 1.490441918373108\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 36 | global_acc: 47.411% | global_loss: 1.4902372360229492\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "comm_round: 37 | global_acc: 47.411% | global_loss: 1.4904860258102417\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 38 | global_acc: 47.411% | global_loss: 1.4902702569961548\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 39 | global_acc: 47.411% | global_loss: 1.490457534790039\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 40 | global_acc: 47.411% | global_loss: 1.490495204925537\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 41 | global_acc: 47.411% | global_loss: 1.490123987197876\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 42 | global_acc: 47.411% | global_loss: 1.4906785488128662\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 43 | global_acc: 47.411% | global_loss: 1.4903345108032227\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 44 | global_acc: 47.411% | global_loss: 1.4904272556304932\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 45 | global_acc: 47.411% | global_loss: 1.4905227422714233\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 46 | global_acc: 47.411% | global_loss: 1.489866852760315\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 47 | global_acc: 47.411% | global_loss: 1.490573763847351\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 48 | global_acc: 47.411% | global_loss: 1.4907970428466797\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 49 | global_acc: 47.411% | global_loss: 1.4908074140548706\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 50 | global_acc: 47.411% | global_loss: 1.4905630350112915\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "comm_round: 51 | global_acc: 47.411% | global_loss: 1.4907020330429077\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 52 | global_acc: 47.411% | global_loss: 1.4903920888900757\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 53 | global_acc: 47.411% | global_loss: 1.4905617237091064\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 54 | global_acc: 47.411% | global_loss: 1.4902347326278687\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 55 | global_acc: 47.411% | global_loss: 1.4903016090393066\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 56 | global_acc: 47.411% | global_loss: 1.4903310537338257\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 57 | global_acc: 47.411% | global_loss: 1.49018132686615\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 58 | global_acc: 47.411% | global_loss: 1.490487813949585\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 59 | global_acc: 47.411% | global_loss: 1.4902961254119873\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 60 | global_acc: 47.411% | global_loss: 1.490297555923462\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 61 | global_acc: 47.411% | global_loss: 1.4904478788375854\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 62 | global_acc: 47.411% | global_loss: 1.4903165102005005\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 63 | global_acc: 47.411% | global_loss: 1.4901700019836426\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 64 | global_acc: 47.411% | global_loss: 1.4901589155197144\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 65 | global_acc: 47.411% | global_loss: 1.4902263879776\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 66 | global_acc: 47.411% | global_loss: 1.4904110431671143\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "comm_round: 67 | global_acc: 47.411% | global_loss: 1.4900457859039307\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 68 | global_acc: 47.411% | global_loss: 1.4900554418563843\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 69 | global_acc: 47.411% | global_loss: 1.4902315139770508\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 70 | global_acc: 47.411% | global_loss: 1.4903206825256348\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 71 | global_acc: 47.411% | global_loss: 1.4905585050582886\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 72 | global_acc: 47.411% | global_loss: 1.4907580614089966\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 73 | global_acc: 47.411% | global_loss: 1.4902924299240112\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 74 | global_acc: 47.411% | global_loss: 1.4905074834823608\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 75 | global_acc: 47.411% | global_loss: 1.4905084371566772\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 76 | global_acc: 47.411% | global_loss: 1.4906519651412964\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 77 | global_acc: 47.411% | global_loss: 1.4906809329986572\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 78 | global_acc: 47.411% | global_loss: 1.4905155897140503\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 79 | global_acc: 47.411% | global_loss: 1.4906840324401855\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 80 | global_acc: 47.411% | global_loss: 1.4903628826141357\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 81 | global_acc: 47.411% | global_loss: 1.490412712097168\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 82 | global_acc: 47.411% | global_loss: 1.4904401302337646\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 83 | global_acc: 47.411% | global_loss: 1.4902302026748657\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 84 | global_acc: 47.411% | global_loss: 1.4903857707977295\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 85 | global_acc: 47.411% | global_loss: 1.4904532432556152\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 86 | global_acc: 47.411% | global_loss: 1.4907073974609375\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 87 | global_acc: 47.411% | global_loss: 1.4905093908309937\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 88 | global_acc: 47.411% | global_loss: 1.4905037879943848\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 89 | global_acc: 47.411% | global_loss: 1.4904751777648926\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 90 | global_acc: 47.411% | global_loss: 1.4906587600708008\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 91 | global_acc: 47.411% | global_loss: 1.4905180931091309\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 92 | global_acc: 47.411% | global_loss: 1.4903522729873657\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 93 | global_acc: 47.411% | global_loss: 1.4904793500900269\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 94 | global_acc: 47.411% | global_loss: 1.4904110431671143\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 95 | global_acc: 47.411% | global_loss: 1.4903745651245117\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 96 | global_acc: 47.411% | global_loss: 1.490631341934204\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "comm_round: 97 | global_acc: 47.411% | global_loss: 1.4903255701065063\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 98 | global_acc: 47.411% | global_loss: 1.4903496503829956\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "comm_round: 99 | global_acc: 47.411% | global_loss: 1.4905306100845337\n"
     ]
    }
   ],
   "source": [
    "#global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(50176, 5)\n",
    "        \n",
    "#global model training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # global model's weights - initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data \n",
    "    client_names= list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(50176, 5)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #local model weight = weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=10, verbose=0)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory\n",
    "        K.clear_session()\n",
    "        \n",
    "    # the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 9ms/step\n",
      "comm_round: 1 | global_acc: 74.387% | global_loss: 1.2148629426956177\n"
     ]
    }
   ],
   "source": [
    "SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(320)\n",
    "smlp_SGD = SimpleMLP()\n",
    "SGD_model = smlp_SGD.build(50176, 5) \n",
    "\n",
    "SGD_model.compile(loss=loss, \n",
    "              optimizer=optimizer, \n",
    "              metrics=metrics)\n",
    "\n",
    "# fit the SGD training data to model\n",
    "_ = SGD_model.fit(SGD_dataset, epochs=160, verbose=0)\n",
    "\n",
    "#test the SGD global model and print out metrics\n",
    "for(X_test, Y_test) in test_batched:\n",
    "        SGD_acc, SGD_loss = test_model(X_test, Y_test, SGD_model, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91c96dd0826ea2944b822806b8952d234d3e059920f4e7872e6b50a950f5a5e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
